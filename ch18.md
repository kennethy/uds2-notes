## 18. Network load balancing
- General rule of thumb: try to keep applications state-less by pushing state to third-party services.
- A load balancer could add or remove nodes based on the load of the system, without the clients knowing. The requests are also distributed among the pool of nodes, providing availability and better performance.
- Load balancing increasing the theoretical availability: with N servers, the probability of all of them being unavailable is the product of the servers' failure rates (e.g. `1 - (0.99 * 0.99) = 0.9999`).
  - We also need to account for the fact that faulty servers are not immediately removed in practice.
  - The remaining healthy servers might not be able to sustain the sudden increase in load.
- Core features provided by a load balancer:
  - Load balancing
    - It can periodically sample a dedicated `load` endpoint expose don each server to measure how busy the server is. This may be expensive since it needs to query all servers.
      - Responses can be cached, but this leads to the inaccurate measurement of how busy the server really is.
      - Randomly distributing requests to servers without accounting for their load leads to a better load distribution.
      - What works well in practice: randomly pick two servers from the pool and route the request to the least loaded one out of the two.
  - Service discovery
    - Main mechanism to allow load balancer to discover the pool of available servers.
    - Fault tolerant coordination service: ZooKeeper or etcd.
    - When a new server comes online, it registers itself to the coordination service with a TTL.
    - A server is removed from the pool once the TTL expires or if it unregisters itself explicitly.
  - Health checks
    - Two main types of health checks: passive and active
    - Passive health check: when a load balancer receives a non-retriable code like 503, it removes the server from the pool.
    - Active health check: when downstream servers expose a dedicated `health` endpoint that can be queried by the load balancer.
      - Timeout is considered as unavailable.
      - The `health` endpoint could also determine the health of the server by comparing metrics (like CPU, available memory, concurrent requests being served) with configurable thresholds.
      - In practice: the load balancer may consider health checks to be unreliable if a majority of the servers are unhealthy, due to a bug in the `health` handler.
      - During an update, the servers can mark themselves as unhealthy, so they stop receiving new requests while allowing the in-flight requests to complete (draining).
      - If there is a rare memory leak issue, the server could also automatically be marked as unhealthy to force a restart. This allows the system to self-heal while the developers have time to figure out what the issue is.
        - A `watchdog` is used that wakes up periodically to monitor server's health.

### 18.1 DNS load balancing
- A simple implementation of a load balancer is with DNS.
  - Add the list of public IP addresses of the servers in the application's DNS record.
  - The client choose one of the addresses.
  - Drawback: DNS server continue to serve the IP of the degraded server when it went down. There could be a delay before the DNS record is propagated to clients (since they are often cached).
  - In practice: DNS load balancing is used when we need to distribute traffic to different data centers in different regions.

### 18.2 Transport layer load balancing
- Load balancing can also be implemented at the TCP level of the network stack (L4 load balancer).
- A network load balancer has one/more physical network interface cards mapped to one or more virtual IP addresses.
- A virutal IP is associated to a pool of servers.
- Clients only see the virtual IP and have no visibility to the individual servers associated with it.
- All traffics flow through the load balancer. This allows the load balancer to detect faulty servers as it has to shuffle packets back and forth between the client and the server.
- A connection is identified by a tuple (source IP/port, destination IP/port).
  - Consistent hashing could be used to minimize disruptions as servers are added or removed.
- The load balancer translates each packet's source address to the load balancer's address, and its destination address to the server's address (and vice versa).
- It's possible the data going out of the servers are greater than the data coming in, `direct server return` is used to allow servers to bypass the load balancer and respond directly to the clients.
- Drawback: L4 load balancers have no understanding of the bytes they move around. As a result, they don't support features that require higher-level network protocols (e.g. terminating TLS connections).
- Suitable to prevent certain DDOS attacks (e.g. SYN flood).

### 18.3 Application layer load balancing
- L7 load balancer is an HTTP reverse-proxy that distributes requests over a pool of servers.
- It requires two TCP connections (client -> LB, LB -> server).
- It leverages multiplexing that allows HTTP requests to share the same TCP connection (i.e. HTTP2).
- It can perform additional optimizations like rate limiting, TLS connections, or force HTTP requests belonging to the same logical session to be routed to the same server.
- It has lower throughput than L4 load balancers.
- Drawback: if the dedicated load balancer goes down, the application behind it does too.
- For internal clients, load balancing can be delegated to them using the sidecar pattern.
- Popular sidecar proxy load balancers: NGINX, HAProxy, Envoy